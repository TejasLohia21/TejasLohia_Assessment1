{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b69dec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./lab4/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./lab4/lib/python3.12/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lab4/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lab4/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./lab4/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./lab4/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68714b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydriller\n",
    "import csv\n",
    "from pydriller import Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95050ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: butterknife\n",
      "--> CSV file size has reached 5.01 MB.\n",
      "--> CSV file size has reached 10.00 MB.\n",
      "--> CSV file size has reached 15.01 MB.\n",
      "Processing repository: retrofit\n",
      "--> CSV file size has reached 20.01 MB.\n",
      "--> CSV file size has reached 25.01 MB.\n",
      "--> CSV file size has reached 30.01 MB.\n",
      "--> CSV file size has reached 35.00 MB.\n",
      "--> CSV file size has reached 40.01 MB.\n",
      "--> CSV file size has reached 45.03 MB.\n",
      "--> CSV file size has reached 50.01 MB.\n",
      "--> CSV file size has reached 55.00 MB.\n",
      "--> CSV file size has reached 60.03 MB.\n",
      "Processing repository: glide\n",
      "--> CSV file size has reached 65.02 MB.\n",
      "--> CSV file size has reached 70.01 MB.\n",
      "--> CSV file size has reached 75.00 MB.\n",
      "--> CSV file size has reached 80.01 MB.\n",
      "--> CSV file size has reached 85.01 MB.\n",
      "--> CSV file size has reached 90.00 MB.\n",
      "--> CSV file size has reached 95.00 MB.\n",
      "--> CSV file size has reached 100.00 MB.\n",
      "--> CSV file size has reached 105.01 MB.\n",
      "--> CSV file size has reached 110.01 MB.\n",
      "--> CSV file size has reached 115.00 MB.\n",
      "--> CSV file size has reached 120.03 MB.\n",
      "--> CSV file size has reached 125.01 MB.\n",
      "--> CSV file size has reached 130.01 MB.\n",
      "--> CSV file size has reached 135.01 MB.\n",
      "--> CSV file size has reached 140.00 MB.\n",
      "--> CSV file size has reached 145.02 MB.\n",
      "--> CSV file size has reached 150.00 MB.\n",
      "--> CSV file size has reached 155.00 MB.\n",
      "--> CSV file size has reached 160.00 MB.\n",
      "\n",
      "Analysis finished. Results are in diff_analysis.csv\n",
      "Number of 'Yes' in Discrepancy: 1108\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "from pydriller import Repository\n",
    "from git import Repo\n",
    "\n",
    "\n",
    "local_repo_paths = [\n",
    "    \"/Users/tejasmacipad/Desktop/Third_year/STT/lab4/butterknife\",\n",
    "    \"/Users/tejasmacipad/Desktop/Third_year/STT/lab4/retrofit\",\n",
    "    \"/Users/tejasmacipad/Desktop/Third_year/STT/lab4/glide\"\n",
    "]\n",
    "output_csv_filename = \"diff_analysis.csv\"\n",
    "\n",
    "\n",
    "\n",
    "csv_header = [\n",
    "    \"repository_name\", \"old_file_path\", \"new_file_path\", \"commit_SHA\",\n",
    "    \"parent_commit_SHA\", \"commit_message\", \"diff_myers\", \"diff_hist\", \"Discrepancy\"\n",
    "]\n",
    "\n",
    "with open(output_csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(csv_header)\n",
    "\n",
    "    five_mb = 5 * 1024 * 1024 #to measure the growth of csv file (preventive measure so that it does not become too big to process)\n",
    "    printat = five_mb\n",
    "\n",
    "    for path in local_repo_paths: #choosing each of the repository\n",
    "        print(f\"Processing repository: {os.path.basename(path)}\")\n",
    "\n",
    "        try:\n",
    "            for commit in Repository(path).traverse_commits(): #traversing across each of the repo\n",
    "                if not commit.parents:\n",
    "                    continue \n",
    "\n",
    "                parent_sha = commit.parents[0] #taking parent of the current commit, [0] used to avoid issues in case of merging commit\n",
    "\n",
    "                for mod in commit.modified_files:\n",
    "                    if mod.filename.endswith(('.png', '.jpg', '.jpeg', '.gif', '.zip')): #ignoring the processing on the files which are in the binary format\n",
    "                         continue\n",
    "\n",
    "                    filepathdiff = mod.new_path or mod.old_path #getting the parth of the current committed commit, we take or with mod.old_path to avoid exception in case where the file might have been deleted later on\n",
    "                    if not filepathdiff: \n",
    "                        continue \n",
    "\n",
    "                    common_args = [\"git\", \"-C\", path, \"diff\", parent_sha, commit.hash, \"--\", filepathdiff] #this is the parser or arg to the command to find the differences for all the valid and filtered commits.\n",
    "                    \n",
    "                    # Build args with the algorithm flag BEFORE the \"--\"\n",
    "                    myers_args = [\n",
    "                        \"git\", \"-C\", path, \"diff\", \"--diff-algorithm=myers\", \"--no-color\",\n",
    "                        parent_sha, commit.hash, \"--\", filepathdiff\n",
    "                    ]\n",
    "                    hist_args = [\n",
    "                        \"git\", \"-C\", path, \"diff\", \"--diff-algorithm=histogram\", \"--no-color\",\n",
    "                        parent_sha, commit.hash, \"--\", filepathdiff\n",
    "                    ]\n",
    "\n",
    "                    myers_proc = subprocess.run(myers_args, capture_output=True, text=True, encoding=\"utf-8\", errors=\"ignore\")\n",
    "                    hist_proc  = subprocess.run(hist_args,  capture_output=True, text=True, encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "                    myers_diff_text = myers_proc.stdout #diff according to the myers algorithm\n",
    "                    hist_diff_text = hist_proc.stdout #diff according to the hist_diff_text algorithm\n",
    "\n",
    "                    norm_myers = \"\\n\".join([re.sub(r'\\s+', '', line) for line in myers_diff_text.splitlines() if re.sub(r'\\s+', '', line)]) #normalization as mentioned in the question\n",
    "                    norm_hist = \"\\n\".join([re.sub(r'\\s+', '', line) for line in hist_diff_text.splitlines() if re.sub(r'\\s+', '', line)])\n",
    "\n",
    "                    discrepancy_found = \"Yes\" if norm_myers != norm_hist else \"No\" # manual check, if they exactly overal then no discrepancy which is the majority case, else \"Yes\"\n",
    "                    \n",
    "                    csv_writer.writerow([ #writing the extracted content to the csv file\n",
    "                        os.path.basename(path), mod.old_path, mod.new_path,\n",
    "                        commit.hash, parent_sha, commit.msg,\n",
    "                        myers_diff_text, hist_diff_text, discrepancy_found\n",
    "                    ])\n",
    "\n",
    "                    current_size = os.path.getsize(output_csv_filename)\n",
    "                    if current_size >= printat:\n",
    "                        size_in_mb = current_size / (1024 * 1024)\n",
    "                        print(f\"--> CSV file size has reached {size_in_mb:.2f} MB.\")\n",
    "                        printat += five_mb \n",
    "\n",
    "        except Exception as error:\n",
    "            print(f\"An error  processing {os.path.basename(path)}: {error}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\nAnalysis finished. Results are in {output_csv_filename}\")\n",
    "df = pd.read_csv(\"diff_analysis.csv\")\n",
    "row = df[\"Discrepancy\"]\n",
    "yes_count = (row.str.strip().str.lower() == \"yes\").sum()\n",
    "print(f\"Number of 'Yes' in Discrepancy: {yes_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e12c2991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Total_Files  Mismatches  Mismatch_%\n",
      "file_category                                     \n",
      "LICENSE                 17           0     0.00000\n",
      "Other                 7149          52     0.72737\n",
      "README                 381          12     3.14961\n",
      "Source code          14515         616     4.24389\n",
      "Test code             9282         428     4.61108\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"diff_analysis.csv\")\n",
    "\n",
    "def categorize_file(path):\n",
    "    if pd.isna(path):\n",
    "        return \"Other\"\n",
    "    path = path.lower()\n",
    "    \n",
    "    if \"test\" in path:\n",
    "        return \"Test code\"\n",
    "    \n",
    "    source_exts = (\".py\", \".java\", \".c\", \".cpp\", \".h\", \".hpp\", \".js\", \".ts\", \".go\", \".rb\", \".swift\")\n",
    "    if path.endswith(source_exts):\n",
    "        return \"Source code\"\n",
    "    \n",
    "    if \"readme\" in path:\n",
    "        return \"README\"\n",
    "    \n",
    "    if \"license\" in path:\n",
    "        return \"LICENSE\"\n",
    "    \n",
    "    return \"Other\"\n",
    "\n",
    "df[\"file_category\"] = df[\"new_file_path\"].fillna(df[\"old_file_path\"]).apply(categorize_file)\n",
    "\n",
    "summary = (\n",
    "    df.groupby(\"file_category\")\n",
    "    .agg(\n",
    "        Total_Files=(\"file_category\", \"size\"),\n",
    "        Mismatches=(\"Discrepancy\", lambda x: (x == \"Yes\").sum())\n",
    "    )\n",
    ")\n",
    "\n",
    "summary[\"Mismatch_%\"] = (summary[\"Mismatches\"] / summary[\"Total_Files\"] * 100).round(5)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a233942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TejasLohia1.4'...\n",
      "warning: You appear to have cloned an empty repository.\n"
     ]
    }
   ],
   "source": [
    "!git clone git@github.com:TejasLohia21/TejasLohia1.4.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad928c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
